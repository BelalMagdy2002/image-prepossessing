{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9560bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Model Structure\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def split_data_by_class(source_dir, train_dir, val_dir, split_ratio=0.7):\n",
    "    # Create train and validation directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    # Get the list of all classes (subdirectories) in the source directory\n",
    "    classes = os.listdir(source_dir)\n",
    "    classes = [cls for cls in classes if os.path.isdir(os.path.join(source_dir, cls))]  # Filter only directories\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_source_dir = os.path.join(source_dir, cls)\n",
    "        class_train_dir = os.path.join(train_dir, cls)\n",
    "        class_val_dir = os.path.join(val_dir, cls)\n",
    "        \n",
    "        # Create class directories in train and validation directories\n",
    "        os.makedirs(class_train_dir, exist_ok=True)\n",
    "        os.makedirs(class_val_dir, exist_ok=True)\n",
    "        \n",
    "        # Get list of files (images) in the class directory\n",
    "        files = os.listdir(class_source_dir)\n",
    "        files = [file for file in files if file.endswith('.jpg') or file.endswith('.png')]  # Filter only image files\n",
    "        \n",
    "        # Shuffle the list of files randomly\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        # Calculate the split index based on the split ratio\n",
    "        split_index = int(len(files) * split_ratio)\n",
    "        \n",
    "        # Copy files to train directory\n",
    "        for file in files[:split_index]:\n",
    "            src_path = os.path.join(class_source_dir, file)\n",
    "            dst_path = os.path.join(class_train_dir, file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        \n",
    "        # Copy files to validation directory\n",
    "        for file in files[split_index:]:\n",
    "            src_path = os.path.join(class_source_dir, file)\n",
    "            dst_path = os.path.join(class_val_dir, file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Define directories and parameters\n",
    "source_data_dir = 'source/'  # Directory containing class subdirectories\n",
    "train_data_dir = 'train/'  # Directory for training data\n",
    "validation_data_dir = 'test/'  # Directory for validation data\n",
    "split_ratio = 0.8  # Ratio for splitting data into training and validation sets\n",
    "\n",
    "# Split data by class into train and validation sets\n",
    "split_data_by_class(source_data_dir, train_data_dir, validation_data_dir, split_ratio)\n",
    "\n",
    "# Function to create a CNN model with the specified architecture\n",
    "def create_simple_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Define model and compile it with specified learning rate and other parameters\n",
    "input_shape = (150, 150, 3)  # Updated input shape\n",
    "num_classes = len(os.listdir(source_data_dir))  # Number of classes based on directories\n",
    "model = create_simple_model(input_shape, num_classes)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create ImageDataGenerators for train and validation data\n",
    "batch_size = 32\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('artifact_recognition_model.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa3c0be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Second Model Structure\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "def split_data_by_class(source_dir, train_dir, val_dir, split_ratio=0.85):\n",
    "    # Create train and validation directories if they don't exist\n",
    "    os.makedirs(train_dir, exist_ok=True)\n",
    "    os.makedirs(val_dir, exist_ok=True)\n",
    "    \n",
    "    # Get the list of all classes (subdirectories) in the source directory\n",
    "    classes = os.listdir(source_dir)\n",
    "    classes = [cls for cls in classes if os.path.isdir(os.path.join(source_dir, cls))]  # Filter only directories\n",
    "    \n",
    "    for cls in classes:\n",
    "        class_source_dir = os.path.join(source_dir, cls)\n",
    "        class_train_dir = os.path.join(train_dir, cls)\n",
    "        class_val_dir = os.path.join(val_dir, cls)\n",
    "        \n",
    "        # Create class directories in train and validation directories\n",
    "        os.makedirs(class_train_dir, exist_ok=True)\n",
    "        os.makedirs(class_val_dir, exist_ok=True)\n",
    "        \n",
    "        # Get list of files (images) in the class directory\n",
    "        files = os.listdir(class_source_dir)\n",
    "        files = [file for file in files if file.endswith('.jpg') or file.endswith('.png')]  # Filter only image files\n",
    "        \n",
    "        # Shuffle the list of files randomly\n",
    "        random.shuffle(files)\n",
    "        \n",
    "        # Calculate the split index based on the split ratio\n",
    "        split_index = int(len(files) * split_ratio)\n",
    "        \n",
    "        # Copy files to train directory\n",
    "        for file in files[:split_index]:\n",
    "            src_path = os.path.join(class_source_dir, file)\n",
    "            dst_path = os.path.join(class_train_dir, file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "        \n",
    "        # Copy files to validation directory\n",
    "        for file in files[split_index:]:\n",
    "            src_path = os.path.join(class_source_dir, file)\n",
    "            dst_path = os.path.join(class_val_dir, file)\n",
    "            shutil.copy(src_path, dst_path)\n",
    "\n",
    "# Define directories and parameters\n",
    "source_data_dir = 'source/'  # Directory containing class subdirectories\n",
    "train_data_dir = 'train/'  # Directory for training data\n",
    "validation_data_dir = 'test/'  # Directory for validation data\n",
    "split_ratio = 0.85  # Ratio for splitting data into training and validation sets\n",
    "\n",
    "# Split data by class into train and validation sets\n",
    "split_data_by_class(source_data_dir, train_data_dir, validation_data_dir, split_ratio)\n",
    "\n",
    "# Function to create a CNN model with the specified architecture\n",
    "def create_simple_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(2, 2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Define model and compile it with specified learning rate and other parameters\n",
    "input_shape = (224, 224, 3)  # Updated input shape\n",
    "num_classes = len(os.listdir(source_data_dir))  # Number of classes based on directories\n",
    "model = create_simple_model(input_shape, num_classes)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create ImageDataGenerators for train and validation data\n",
    "batch_size = 16\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "epochs = 50\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=epochs,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Save the trained model\n",
    "model.save('artifact_recognition_model.h5')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
